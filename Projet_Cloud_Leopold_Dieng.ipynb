{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "86b57c5d-4883-45bc-9a1d-a4e7d68169b7",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------- Traitement du fichier: input/error1.csv\n",
      "Valeur non numérique pour transaction_id à la ligne 2\n",
      "Valeur non numérique pour quantity à la ligne 3\n",
      "2 erreurs détectées. Déplacement du fichier dans '/test_error/'.\n",
      "Fichier déplacé vers error/error1.csv \n",
      "\n",
      "---------------- Traitement du fichier: input/error2.csv\n",
      "Valeur non numérique pour price à la ligne 1\n",
      "Valeur non numérique pour quantity à la ligne 3\n",
      "2 erreurs détectées. Déplacement du fichier dans '/test_error/'.\n",
      "Fichier déplacé vers error/error2.csv \n",
      "\n",
      "---------------- Traitement du fichier: input/error3.csv\n",
      "Valeur non numérique pour quantity à la ligne 3\n",
      "1 erreurs détectées. Déplacement du fichier dans '/test_error/'.\n",
      "Fichier déplacé vers error/error3.csv \n",
      "\n",
      "---------------- Traitement du fichier: input/error4.csv\n",
      "Valeur non numérique pour quantity à la ligne 3\n",
      "1 erreurs détectées. Déplacement du fichier dans '/test_error/'.\n",
      "Fichier déplacé vers error/error4.csv \n",
      "\n",
      "---------------- Traitement du fichier: input/error5.csv\n",
      "Valeur négative non autorisée pour price à la ligne 1\n",
      "Valeur non numérique pour quantity à la ligne 3\n",
      "2 erreurs détectées. Déplacement du fichier dans '/test_error/'.\n",
      "Fichier déplacé vers error/error5.csv \n",
      "\n",
      "---------------- Traitement du fichier: input/transactions.csv\n",
      "Validation réussie !\n",
      "Aucune erreur détectée. Déplacement du fichier dans '/clean/'.\n",
      "Fichier déplacé vers clean/transactions.csv \n",
      "\n",
      "Traitement du fichier : clean/transactions.csv\n",
      "Données du fichier input/transactions.csv insérées dans la table isi-group-m2-dsia.dataset_dieng_leopold.transactions\n",
      "Fichier déplacé vers done/transactions.csv \n",
      "\n",
      "Chargement dans la base de données 'transactions' réussie ! \n",
      " \n",
      " ----------------- FIN DU PROGRAMME --------------- \n",
      " \n"
     ]
    }
   ],
   "source": [
    "from google.cloud import storage\n",
    "from google.cloud import bigquery\n",
    "import pandas as pd\n",
    "from io import BytesIO\n",
    "\n",
    "# Paramètres de configuration\n",
    "nom_projet = \"isi-group-m2-dsia\"\n",
    "nom_bucket = \"m2dsia-dieng-leopold-data\"\n",
    "nom_table = \"isi-group-m2-dsia.dataset_dieng_leopold.transactions\"\n",
    "\n",
    "\n",
    "# Initialisation des clients Storage et BigQuery\n",
    "client_storage = storage.Client(project=nom_projet)\n",
    "bucket = client_storage.bucket(nom_bucket)\n",
    "client_bigquery = bigquery.Client(project=nom_projet)\n",
    "\n",
    "\n",
    "# Liste des fichiers dans le dossier 'test_input/'\n",
    "liste_fichiers = bucket.list_blobs(prefix='input/')\n",
    "\n",
    "for fichier_csv in liste_fichiers:\n",
    "    if fichier_csv.name.endswith('.csv'):  # Filtrer uniquement les fichiers CSV\n",
    "        print(f\"---------------- Traitement du fichier: {fichier_csv.name}\")\n",
    "\n",
    "        # Lecture du fichier CSV depuis le bucket\n",
    "        contenu_fichier = fichier_csv.download_as_bytes()\n",
    "        df = pd.read_csv(BytesIO(contenu_fichier))\n",
    "\n",
    "        # Convertir la colonne `date` en type datetime avec gestion des erreurs\n",
    "        if 'date' in df.columns:\n",
    "            df['date'] = pd.to_datetime(df['date'], format='%m/%d/%Y', errors='coerce')\n",
    "\n",
    "        # Schéma de validation\n",
    "        schema = {\n",
    "            'transaction_id': {'type': int, 'required': True, 'unique': True, 'nullable': False},\n",
    "            'product_name': {'type': str, 'nullable': False},\n",
    "            'category': {'type': str, 'nullable': False},\n",
    "            'price': {'type': float, 'nullable': False},\n",
    "            'quantity': {'type': int, 'nullable': False},\n",
    "            'date': {'type': pd.Timestamp, 'nullable': False},\n",
    "            'customer_name': {'type': str, 'nullable': True},\n",
    "            'customer_email': {'type': str, 'nullable': True}\n",
    "        }\n",
    "\n",
    "        # Validation des données\n",
    "        erreurs = []\n",
    "        for indice, ligne in df.iterrows():\n",
    "            for colonne, regles in schema.items():\n",
    "                # ... (vos autres vérifications) ...\n",
    "\n",
    "                # Vérification des valeurs négatives\n",
    "                if colonne in ['transaction_id', 'price', 'quantity'] and not pd.isna(ligne[colonne]):\n",
    "                    try:\n",
    "                        # Convertir la valeur en numérique avant la comparaison\n",
    "                        if isinstance(ligne[colonne], int):\n",
    "                            valeur = ligne[colonne]\n",
    "                        else:\n",
    "                            valeur = float(ligne[colonne])\n",
    "\n",
    "                        if valeur < 0:\n",
    "                            erreurs.append(f\"Valeur négative non autorisée pour {colonne} à la ligne {indice + 1}\")\n",
    "                    except ValueError:\n",
    "                        # Gérer le cas où la conversion échoue (la valeur n'est pas numérique)\n",
    "                        erreurs.append(f\"Valeur non numérique pour {colonne} à la ligne {indice + 1}\")\n",
    "\n",
    "        # Affichage des erreurs\n",
    "        if erreurs:\n",
    "            for erreur in erreurs:\n",
    "                print(erreur)\n",
    "        else:\n",
    "            print(\"Validation réussie !\")\n",
    "\n",
    "        # Déplacer les fichiers dans les dossiers appropriés\n",
    "        if erreurs:\n",
    "            # Fichiers avec erreurs -> /test_error/\n",
    "            print(f\"{len(erreurs)} erreurs détectées. Déplacement du fichier dans '/test_error/'.\")\n",
    "            nom_blob_destination = fichier_csv.name.replace(\"input/\", \"error/\")\n",
    "        else:\n",
    "            # Fichiers sans erreurs -> /test_clean/\n",
    "            print(\"Aucune erreur détectée. Déplacement du fichier dans '/clean/'.\")\n",
    "            nom_blob_destination = fichier_csv.name.replace(\"input/\", \"clean/\")\n",
    "\n",
    "        # Copier le fichier vers le nouvel emplacement\n",
    "        nouveau_blob = bucket.blob(nom_blob_destination)\n",
    "        nouveau_blob.rewrite(fichier_csv)\n",
    "\n",
    "        # Supprimer l'ancien fichier\n",
    "        fichier_csv.delete()\n",
    "        print(f\"Fichier déplacé vers {nom_blob_destination} \\n\")\n",
    "\n",
    "# Liste des fichiers dans le dossier 'test_clean/'\n",
    "fichiers_csv = bucket.list_blobs(prefix='clean/')\n",
    "\n",
    "for fichier in fichiers_csv:\n",
    "    if fichier.name.endswith('.csv'):  # Filtrer uniquement les fichiers CSV\n",
    "        print(f\"Traitement du fichier : {fichier.name}\")\n",
    "\n",
    "        # Lecture du fichier CSV depuis le bucket\n",
    "        contenu = fichier.download_as_bytes()\n",
    "        df = pd.read_csv(BytesIO(contenu))\n",
    "\n",
    "        # Convertir la colonne `date` en type datetime avec gestion des erreurs\n",
    "        if 'date' in df.columns:\n",
    "            df['date'] = pd.to_datetime(df['date'], format='%m/%d/%Y', errors='coerce')\n",
    "\n",
    "        # Insertion des données dans BigQuery\n",
    "        try:\n",
    "            parametres_insertion = bigquery.LoadJobConfig(\n",
    "                schema=[\n",
    "                    bigquery.SchemaField(\"transaction_id\", \"INTEGER\", mode=\"REQUIRED\"),\n",
    "                    bigquery.SchemaField(\"product_name\", \"STRING\", mode=\"REQUIRED\"),\n",
    "                    bigquery.SchemaField(\"category\", \"STRING\", mode=\"REQUIRED\"),\n",
    "                    bigquery.SchemaField(\"price\", \"FLOAT\", mode=\"REQUIRED\"),\n",
    "                    bigquery.SchemaField(\"quantity\", \"INTEGER\", mode=\"REQUIRED\"),\n",
    "                    bigquery.SchemaField(\"date\", \"DATE\", mode=\"REQUIRED\"),\n",
    "                    bigquery.SchemaField(\"customer_name\", \"STRING\", mode=\"NULLABLE\"),\n",
    "                    bigquery.SchemaField(\"customer_email\", \"STRING\", mode=\"NULLABLE\")\n",
    "                ],\n",
    "                write_disposition=\"WRITE_APPEND\",  # Ajouter les données à la table existante\n",
    "                # Ignorer la première ligne (en-tête)\n",
    "                skip_leading_rows=1,\n",
    "                source_format=bigquery.SourceFormat.CSV \n",
    "            )\n",
    "\n",
    "            # Conversion du DataFrame en CSV pour l'insertion\n",
    "            csv_data = df.to_csv(index=False) \n",
    "\n",
    "            # Charger les données depuis une chaîne de caractères CSV\n",
    "            job = client_bigquery.load_table_from_file(\n",
    "                BytesIO(csv_data.encode()), nom_table, job_config=job_config\n",
    "            )\n",
    "            job.result()  # Attendre que l'insertion soit terminée\n",
    "\n",
    "            print(f\"Données du fichier {fichier_csv.name} insérées dans la table {nom_table}\")\n",
    "\n",
    "            # Déplacer le fichier vers le dossier /done/\n",
    "            nom_blob_destination = fichier.name.replace(\"clean/\", \"done/\")\n",
    "            nouveau_blob = bucket.blob(nom_blob_destination)\n",
    "            nouveau_blob.rewrite(fichier)\n",
    "            fichier.delete()\n",
    "            print(f\"Fichier déplacé vers {nom_blob_destination} \\n\")\n",
    "            print(\"Chargement dans la base de données 'transactions' réussie ! \\n \")\n",
    "            print(\" ----------------- FIN DU PROGRAMME --------------- \\n \")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Erreur lors de l'insertion des données dans BigQuery: {e}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "634510d8-272d-4f09-8874-c39e31a79f2d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
